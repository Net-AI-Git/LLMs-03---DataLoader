{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Net-AI-Git/LLMs-03---DataLoader/blob/main/DataLoader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvMSnTlnPBzw"
      },
      "outputs": [],
      "source": [
        "!pip install nltk\n",
        "!pip install transformers==4.42.1\n",
        "!pip install sentencepiece\n",
        "!pip install spacy\n",
        "!pip install numpy==1.26.0\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm\n",
        "!pip install torch==2.2.2 torchtext==0.17.2\n",
        "!pip install torchdata==0.7.1\n",
        "!pip install portalocker\n",
        "!pip install numpy pandas\n",
        "!pip install numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnxYjoM6PBz0",
        "outputId": "99fea01d-d449-46fe-9dd7-55597ff3d4cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.17.2+cpu\n"
          ]
        }
      ],
      "source": [
        "import torchtext\n",
        "print(torchtext.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU1m7dPSPBz1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from typing import Iterable, List\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
        "import torchtext\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyFoOsHtPBz1"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
        "    \"Fame's a fickle friend, Harry.\",\n",
        "    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n",
        "    \"Soon we must all face the choice between what is right and what is easy.\",\n",
        "    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n",
        "    \"You are awesome!\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjB_i5ERPBz2"
      },
      "outputs": [],
      "source": [
        "# Tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "# Build vocabulary\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, sentences))\n",
        "\n",
        "batch_size = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72IY0S9APBz2"
      },
      "outputs": [],
      "source": [
        "def print_dataloader(dataloader):\n",
        "    '''\n",
        "    Displays each input tensor and its corresponding tokenized\n",
        "    sentence from the DataLoader\n",
        "    '''\n",
        "\n",
        "    # Iterate through the data loader\n",
        "    for batch in dataloader:\n",
        "        for row in batch:\n",
        "            print(f\"input tensor: {row}\")\n",
        "            words = [vocab.get_itos()[idx] for idx in row]\n",
        "            print(f\"tokenized sentence: {words}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcgn_8ZZPBz3"
      },
      "source": [
        "# Method 1: Item-Level Preprocessing\n",
        "## Tokenization and Vocab Mapping in Dataset `__getitem__`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciN_-AXYPBz3"
      },
      "outputs": [],
      "source": [
        "# Define a custom data set\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sentences, tokenizer, vocab):\n",
        "        self.sentences = sentences\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.tokenizer(self.sentences[idx])\n",
        "        # Convert tokens to tensor indices using vocab\n",
        "        tensor_indices = [self.vocab[token] for token in tokens]\n",
        "        return torch.tensor(tensor_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM9U19HwPBz3"
      },
      "outputs": [],
      "source": [
        "# Create a custom collate function\n",
        "def collate_fn(batch):\n",
        "    # Pad sequences within the batch to have equal lengths\n",
        "    padded_batch = pad_sequence(batch, batch_first=True, padding_value=0)\n",
        "    return padded_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcbSrD1BPBz3",
        "outputId": "25477db4-8fc2-4ae8-a2af-19480ec8d469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input tensor: tensor([11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
            "        43, 61,  9, 44,  0, 14,  9, 33,  1])\n",
            "tokenized sentence: ['if', 'you', 'want', 'to', 'know', 'what', 'a', 'man', \"'\", 's', 'like', ',', 'take', 'a', 'good', 'look', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.']\n",
            "\n",
            "input tensor: tensor([35,  6, 16,  3, 38, 40,  0,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
            "tokenized sentence: ['fame', \"'\", 's', 'a', 'fickle', 'friend', ',', 'harry', '.', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n",
            "\n",
            "input tensor: tensor([12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
            "        21,  1])\n",
            "tokenized sentence: ['it', 'is', 'our', 'choices', ',', 'harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '.']\n",
            "\n",
            "input tensor: tensor([54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1,  0,  0,\n",
            "         0,  0])\n",
            "tokenized sentence: ['soon', 'we', 'must', 'all', 'face', 'the', 'choice', 'between', 'what', 'is', 'right', 'and', 'what', 'is', 'easy', '.', ',', ',', ',', ',']\n",
            "\n",
            "input tensor: tensor([66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
            "         2, 12, 64, 17, 26, 65,  1])\n",
            "tokenized sentence: ['youth', 'can', 'not', 'know', 'how', 'age', 'thinks', 'and', 'feels', '.', 'but', 'old', 'men', 'are', 'guilty', 'if', 'they', 'forget', 'what', 'it', 'was', 'to', 'be', 'young', '.']\n",
            "\n",
            "input tensor: tensor([19,  4, 25, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0])\n",
            "tokenized sentence: ['you', 'are', 'awesome', '!', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n",
            "\n",
            "Elapsed time: 0.00893733202246949 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start = time.perf_counter()\n",
        "\n",
        "# Create an instance of your custom data set\n",
        "custom_dataset = CustomDataset(sentences, tokenizer, vocab)\n",
        "\n",
        "# Create a data loader with the custom collate function with batch_first=True,\n",
        "dataloader = DataLoader(custom_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "print_dataloader(dataloader)\n",
        "\n",
        "end = time.perf_counter()\n",
        "print(\"Elapsed time:\", end - start, \"seconds\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOv6KOjZPBz4"
      },
      "source": [
        "# Method 2: Batch-Level Preprocessing  \n",
        "## Tokenization and Vocab Mapping in DataLoader `collate_fn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-SxggsRPBz4"
      },
      "outputs": [],
      "source": [
        "# Define a custom data set\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sentences[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNe1GaQvPBz4"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    # Tokenize each sample in the batch using the specified tokenizer\n",
        "    tensor_batch = []\n",
        "    for sample in batch:\n",
        "        tokens = tokenizer(sample)\n",
        "        # Convert tokens to vocabulary indices and create a tensor for each sample\n",
        "        tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n",
        "\n",
        "    # Pad sequences within the batch to have equal lengths using pad_sequence\n",
        "    # batch_first=True ensures that the tensors have shape (batch_size, max_sequence_length)\n",
        "    padded_batch = pad_sequence(tensor_batch, batch_first=True)\n",
        "\n",
        "    # Return the padded batch\n",
        "    return padded_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKwmRsjhPBz5",
        "outputId": "bfda9b01-202b-458c-c208-00ca66ba7908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input tensor: tensor([12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
            "        21,  1,  0,  0,  0,  0,  0])\n",
            "tokenized sentence: ['it', 'is', 'our', 'choices', ',', 'harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '.', ',', ',', ',', ',', ',']\n",
            "\n",
            "input tensor: tensor([66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
            "         2, 12, 64, 17, 26, 65,  1])\n",
            "tokenized sentence: ['youth', 'can', 'not', 'know', 'how', 'age', 'thinks', 'and', 'feels', '.', 'but', 'old', 'men', 'are', 'guilty', 'if', 'they', 'forget', 'what', 'it', 'was', 'to', 'be', 'young', '.']\n",
            "\n",
            "input tensor: tensor([19,  4, 25, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
            "tokenized sentence: ['you', 'are', 'awesome', '!', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n",
            "\n",
            "input tensor: tensor([11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
            "        43, 61,  9, 44,  0, 14,  9, 33,  1])\n",
            "tokenized sentence: ['if', 'you', 'want', 'to', 'know', 'what', 'a', 'man', \"'\", 's', 'like', ',', 'take', 'a', 'good', 'look', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.']\n",
            "\n",
            "input tensor: tensor([54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1])\n",
            "tokenized sentence: ['soon', 'we', 'must', 'all', 'face', 'the', 'choice', 'between', 'what', 'is', 'right', 'and', 'what', 'is', 'easy', '.']\n",
            "\n",
            "input tensor: tensor([35,  6, 16,  3, 38, 40,  0,  8,  1,  0,  0,  0,  0,  0,  0,  0])\n",
            "tokenized sentence: ['fame', \"'\", 's', 'a', 'fickle', 'friend', ',', 'harry', '.', ',', ',', ',', ',', ',', ',', ',']\n",
            "\n",
            "Elapsed time: 0.00442746898625046 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start = time.perf_counter()\n",
        "\n",
        "# Create an instance of your custom data set\n",
        "custom_dataset = CustomDataset(sentences)\n",
        "\n",
        "# Create a data loader for the custom dataset\n",
        "dataloader = DataLoader(\n",
        "    dataset=custom_dataset,   # Custom PyTorch Dataset containing your data\n",
        "    batch_size=batch_size,     # Number of samples in each mini-batch\n",
        "    shuffle=True,              # Shuffle the data at the beginning of each epoch\n",
        "    collate_fn=collate_fn      # Custom collate function for processing batches\n",
        ")\n",
        "\n",
        "print_dataloader(dataloader)\n",
        "\n",
        "end = time.perf_counter()\n",
        "print(\"Elapsed time:\", end - start, \"seconds\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAp6TgDVPBz5"
      },
      "source": [
        "## Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paLbIb5mPBz5",
        "outputId": "3d845101-b492-4918-d007-6d6964dcabee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijojpdNvPBz6"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1sWdjjgPBz6"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"Ceci est une phrase.\",\n",
        "    \"C'est un autre exemple de phrase.\",\n",
        "    \"Voici une troisième phrase.\",\n",
        "    \"Il fait beau aujourd'hui.\",\n",
        "    \"J'aime beaucoup la cuisine française.\",\n",
        "    \"Quel est ton plat préféré ?\",\n",
        "    \"Je t'adore.\",\n",
        "    \"Bon appétit !\",\n",
        "    \"Je suis en train d'apprendre le français.\",\n",
        "    \"Nous devons partir tôt demain matin.\",\n",
        "    \"Je suis heureux.\",\n",
        "    \"Le film était vraiment captivant !\",\n",
        "    \"Je suis là.\",\n",
        "    \"Je ne sais pas.\",\n",
        "    \"Je suis fatigué après une longue journée de travail.\",\n",
        "    \"Est-ce que tu as des projets pour le week-end ?\",\n",
        "    \"Je vais chez le médecin cet après-midi.\",\n",
        "    \"La musique adoucit les mœurs.\",\n",
        "    \"Je dois acheter du pain et du lait.\",\n",
        "    \"Il y a beaucoup de monde dans cette ville.\",\n",
        "    \"Merci beaucoup !\",\n",
        "    \"Au revoir !\",\n",
        "    \"Je suis ravi de vous rencontrer enfin !\",\n",
        "    \"Les vacances sont toujours trop courtes.\",\n",
        "    \"Je suis en retard.\",\n",
        "    \"Félicitations pour ton nouveau travail !\",\n",
        "    \"Je suis désolé, je ne peux pas venir à la réunion.\",\n",
        "    \"À quelle heure est le prochain train ?\",\n",
        "    \"Bonjour !\",\n",
        "    \"C'est génial !\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYi6iAWhPBz7"
      },
      "outputs": [],
      "source": [
        "def collate_fn_fr(batch):\n",
        "    # Pad sequences within the batch to have equal lengths\n",
        "    tensor_batch = []\n",
        "    for sample in batch:\n",
        "        tokens = tokenizer(sample)\n",
        "        tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n",
        "\n",
        "    padded_batch = pad_sequence(tensor_batch, batch_first=True)\n",
        "    return padded_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sUy3CE0PBz7"
      },
      "outputs": [],
      "source": [
        "# Build tokenizer\n",
        "tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')\n",
        "\n",
        "# Build vocabulary\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, corpus))\n",
        "\n",
        "# Sort sentences based on their length for betther padding\n",
        "sorted_data = sorted(corpus, key=lambda x: len(tokenizer(x)))\n",
        "#print(sorted_data)\n",
        "dataloader = DataLoader(sorted_data, batch_size=4, shuffle=False, collate_fn=collate_fn_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh9aIFlDPBz7",
        "outputId": "57e04d9a-a1f7-4f61-a9a1-557488bf8ec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 27,   2,   0],\n",
            "        [ 26,  45,   2],\n",
            "        [ 35,   8,   2],\n",
            "        [ 25, 101,   2]])\n",
            "tensor([[  1, 105,  41,   0],\n",
            "        [  1,   3,  76,   0],\n",
            "        [  1,   3,  82,   0],\n",
            "        [ 11,   4,  74,   2]])\n",
            "tensor([[ 28,   4,  10,   9,   0],\n",
            "        [ 38,  10, 107,   9,   0],\n",
            "        [ 12,  69,  51,  49,   0],\n",
            "        [  1,  16, 103,  17,   0]])\n",
            "tensor([[  1,   3,  14, 100,   0,   0],\n",
            "        [ 37,   4,  19,  92,  95,   7],\n",
            "        [ 33,  71, 122, 117,  52,   2],\n",
            "        [ 32,  85,  42,  80,  87,   0]])\n",
            "tensor([[ 30,  18,  19,  88,  21,   2,   0],\n",
            "        [ 31,  43,   8,  15,  57,  73,   0],\n",
            "        [ 36,  62,  90, 110,  60,  83,   0],\n",
            "        [ 34, 112, 104, 106, 108,  56,   0]])\n",
            "tensor([[ 11,   4, 111,  50,  68,   5,   9,   0],\n",
            "        [  1, 113,  55,   6,  86,  53,  47,   0],\n",
            "        [  1,   3,  98,   5, 116,  99,  66,   2],\n",
            "        [120,  97,  75,   4,   6,  93,  20,   7]])\n",
            "tensor([[  1,   3,  14,  20,  58,  44,   6,  72,   0,   0],\n",
            "        [  1,  63,  40,  13,  89,  67,  13,  79,   0,   0],\n",
            "        [  1,   3,  70,  46,  10,  81,  78,   5,  21,   0],\n",
            "        [ 12, 119,  39,   8,   5,  84,  59,  54, 115,   0]])\n",
            "tensor([[ 29,  24,  96, 109,  48,  61,  94,  18,   6, 118,  23,  65,   7],\n",
            "        [  1,   3,  64,  22,  77,  16,  91,  17, 114, 121,  15, 102,   0]])\n"
          ]
        }
      ],
      "source": [
        "for batch in dataloader:\n",
        "    print(batch)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "prev_pub_hash": "abe20e6edc4a44e61449273e27547639ec0a9cf098c42704485b9267fdfad9d5",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}